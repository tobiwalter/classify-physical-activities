# Classify physical activities performed by test subjects based on multimodal sensor data

In this notebook, I visualize and classify data from the [MHEALTH] (http://archive.ics.uci.edu/ml/datasets/mhealth+dataset) dataset, which is available under the following link: The dataset was provided for the purpose of classifying body movements of test subjects based on a variety of sensor data collected from body sensors that were placed on the chest, wrist and ankle. All sensor data is recoreded at a sampling rate of 50 Hz, i.e. 50 datapoints per second. The task belongs to the problem domain of Human Activity Recognition.

This notebook consists of two major parts, the first being an exploratory data analysis and the second being the modelling part in which I try to learn machine learning models that predict the physical activity performed by a test subject based on the multimodal sensing data.
